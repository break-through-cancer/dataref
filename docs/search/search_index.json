{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":".navbar { display: none; } Quick Documents Links | BTC Data Science Hub Proposal | Data Coordinator Duties | Technical Instructions on Staging Data | How to Configure AWS CLI | BTC Data Reference The aim of this page is to serve as a central point of reference for data handling in Break Through Cancer (BTC), capturing the consensus rubric under which data are generated, annotated, aggregated, governed, and accessed. This includes metadata capture during patient enrollment and sample acquisition, standards and processes for molecular assay data generation and pipelines, data flow diagrams providing simplified views, as well as a FAQ for common questions. In concert with BTC Disease TeamLabs, these norms are being codified by the Data Science TeamLab (DST) as a key element of the data science proposal The system and infrastructure which serves as the convergence point for data science activity within BTC is code-named DASH , short for DA ta S cience H ub; and is informed by numerous standards, including F.A.I.R. data practice and NIH guidelines , and draws heavily from lessons learned and software developed in earlier and sister projects, including HTAN , GDC , and TCGA Data Life Cycle Within BTC the flow of data naturally subdivides along the boundaries of institutional and BTC-wide ecosystems: Institutional: data, research, and clinical trial activity typically within the walls of a single instution, performed upon and annotated by institutional systems per their internal practice. Some examples of this could be pre-clinical or basic research results from a single PI lab, or the exported and de-indentified data from a clinical trial data system. DASH: data shared by TeamLabs across institutional boundaries, by way of DASH How DASH maintains identifiers for and provenance of these data is described in more detail below . Planning for Data Sharing Please contact the BTC Programs Team when planning to share data used by or generated in your TeamLab, whether pre-clinical, clinical, or publication data. The PM team will help assess whether there are contractual, institutional, or other encumbrances upon the data that must be cleared first before they may be shared. While planning it's also important to note that: Sharing non-public data via DASH does not confer access to other TeamLabs: such data are initially embargoed, with access limited to members of the submitting TeamLab until the embargo period ends Patient IDs, sample IDs, and related metadata are defined within clinical lab manuals and SOPs: this will help BTC maintain the provenance of material and data as it travels from one institute to another SOPs are in place to remove PHI prior to sharing Sharing/Submitting Data When data are ready to be shared/analyzed via DASH, please contact the data coordinator(s) at your institution: MD Anderson: Tracee Burnsteel MIT: Charles Demurjian (PI: Stuart Levine) Johns Hopkins: Meredith Wetzel (PI: Elana Fertig) Memorial Sloan Kettering: Eli Havasov (PI: Sohrab Shah) Dana Farber: Siri Palreddy (PI: Rameen Beroukhim) The role of the BTC data coordinator is described here . Your data coordinator and the DASH team will be happy to guide data providers through the process of staging data into cloud buckets( ). The staging area * is a data lake -style abstraction: a semi-organized collection of storage bins, stratified by TeamLab, whose contents are provided \"as is,\" with little (or no) formal validation or annotation. TeamLab members may elect to use such staged data immediately, prior to further curation, as needs dictate. * Originally, we allowed teams to stage their data into cloud buckets and Sharepoint, however we now only allow data to be staged in the cloud. Data Curation After staging, many (but not necessarily all) BTC datasets will also be curated, which includes steps such as: validating that shared files do not include PHI, verifying that trial-specific IDs (when applicable) have been associated so that the data may be tracked, and ensuring sufficient metadata have been submitted so that others may productively use the data. As described below , BTC-specific IDs will also be assigned within the DASH database to maintain provenance, enable pan-cancer analysis, and promote data governance (such as sandboxed use during embargo periods). These BTC IDs supplement, rather than replace, any IDs attached at the point of data origination (e.g. in a clinical trial or PI lab) and the mapping between the two will be retained internally by DASH as metadata. Accessing Data Both staged and curated data are summarized in our high-level DASHBoard and may be downloaded interactively from the data browser (temporarily disabled during AWS migration) or programmatically via aws cli for many, large files or pipelined analysis. Additional information is available in the technical instructions (ver 0.7) for data sharing . Finally, recall that staged data are offered \"as is,\" while curated data will soon support more advanced use cases such as querying with fine-grained parameters (e.g. gene name) or visual exploration in familiar tools like cBioPortal , cellxgene , or Minerva as appropriate. Analysis and Pipelines The DST has established joint Protocol and Analysis working groups with disease teams, to: identify analysis needs across TeamLabs, align common SOPs for data generation and QC, coordinate changes as new technologies and needs arise, tie each central analytic pipeline to consumers of its data in each TeamLab, and perform regular check-ins to ensure analytic approaches continue to suit disease TeamLab objectives. For each data type generated across two or more TeamLabs, the DST will provide best-practices pipelines and/or tools for each data level : from Levels 1 and 2 primary data generation (L1, L2) through subsequent L3 and L4 analyses. This work is very active, and a number of analysis pipelines are already available from DFCI , JHU, MDAnderson, NextFlow nf-core and the MIT BioMicroCenter . As these and other pipelines harden towards robust, self-service tools they are also being added to a common, increasingly multi-modal analysis workflow in the BTC Cirro instance . This BTC Cirro instance should be immediately accessible to anyone in BTC via single-sign-on with the same credentials used to access other BTC resources (e.g. SharePoint or Teams). The Cirro platform runs NextFlow and WDL pipelines, and provides powerful tools for computationalists in a modern, easy-to-use interface that is also approachable for non-computationalists. There are over 170 pipeline configurations already available, and we are making project spaces available for each TeamLab that are pre-loaded with that team's data, include all available analysis pipelines, and are by default sandboxed for access only by members of the team. Please contact the DASH team if you would like to contribute pipelines, perform analyses, or would simply like more information. BTC Identifier Scheme As data are added to DASH they are tagged with subject and sample (biospecimen) identifiers as follows: At minimum such IDs will be attached to BTC clinical trial data; and ideally to BTC pre-clinical, basic research, and external data as appropriate (all by way of the scheme described here ). Note that here \u201cbiospecimen\u201d is preferred over \u201csample\u201d for generality and to capture that samples can be subdivided into multiple portions. The association between data file and biospecimen is maintained as metadata within the DASH database, not within the file identifier itself. To see how this ID scheme might play out, here's what a hypothetical data tree for the first subject (patient) of the first BTC glioblastoma multiforme trial might look like Here 6 needle biopsy cores (samples) were extracted; the first of which has been characterized in multiple assays, yielding 8 distinctly molecular data output files (i.e. one per data type). Each interventional timepoint in a longitudinal trial would yield a new sample (or samples) for that subject. Finally, note that BTC may devise study names which encompass the entire set of data generated by a TeamLab, (e.g. a study name of \"GBM\" that might include ALL data from trial 1, trial 2, and so forth). Scope It will help to amplify a point made above in the context of data curation , namely that BTC- identifiers apply only to data AFTER sharing into DASH . These IDs do not replace identifiers attached to data at their point of origin (e.g. in a clinical trial data system, or PI lab research project, or external publication), and in fact those original IDs will be carried along--to the greatest extent possible--as metadata when data are shared into DASH. In other words, DASH does not seek to legislate how data generators identify data within the context of its original use case(s), only how data are identified once they are shared within DASH. Data Entities and Levels As data progress through the BTC life cycle they are processed and transformed through a series of \u201cdata levels.\u201d For each data context (e.g. clinical, imaging, sequencing, spatial) the constituent files of each data level may differ, but in all cases Level 1 represents raw or uncurated data (e.g. directly from an instrument) and each successive level represents a maturation of that data towards analysis and, eventually, publication and wider utilization. Unless explicitly stated otherwise, we propose BTC data infrastructure, processing and analysis adopt existing GDC + HTAN standards and nomenclature, including for clinical , biospecimen , sequencing and imaging data. For convenience, some of those standards will be excerpted below but we refer the reader back to the original material at the given links for an exhaustive treatment. Each disease study in BTC contributes data from 1 or more enrolled Subjects, who have donated Biospecimens. Data files are generated when biospecimens are assayed by an instrument/protocol or processed in downstream SOPs or analyses. Captured metadata enables tracing of any data file back to its source biospecimen. Level 1 raw data files are derived directly from the corresponding biospecimen, whereas processed level 2-4 data files are linked to lower level parent data files. Clinical Data Levels (Tiers) The BTC clinical data model consists of three tiers. Tier 1 aligns with Genomic Data Commons (GDC) guidelines for clinical data, while Tiers 2 and 3 are informed by the HTAN extensions to the GDC model . Clinical data in BTC are still evolving as we develop trial forms and SOPs across institutions. Only Tier1 is encompassed thus far, but no data will be ingested into DASH if it is not (a) fully de-identified and (b) accompanied by minimally viable metadata (biospecimen and/or clinical). Omic Data Levels In alignment with TCGA and the NCI Genomic Data Commons, BTC will categorize multi-omic data into four levels: Level Definition Examples 1 Raw data FASTQs, unaligned BAMs 2 Aligned primary data Aligned BAMs 3 Derived biomolecular data Gene expression matrix files, VCFs, etc 4 Sample level summary data t-SNE plot coordinates, etc These will apply to the multiple assay and sequencing modalities (omic data types) envisioned for BTC , including single-cell and single-nucleus RNA Seq (sc/snRNASeq), single-cell ATAC Seq, bulk RNAseq and Bulk DNAseq. We propose that BTC follow the latest GENCODE version for gene annotations, GENCODE Version 43. GENCODE is used for gene definitions by many consortia, including ENCODE, NCI Genomic Data Commons, Human Cell Atlas, and PCAWG (Pan-Cancer Analysis of Whole Genomes). Ensembl gene content is essentially identical to that of GENCODE (FAQ) and interconversion is possible. We further propose BTC adopt GENCODE 43 Gene Transfer Format (GTF) basic gene annotation file (GENCODE 43 GTF) and filtered files (GENCODE 43 GTF with genes only; GENCODE 43 GTF with genes only and retaining only chromosome X copy of pseudoautosomal region) for gene annotation. BTC may also include external data generated with other gene models, as the process of implementing the standard is ongoing. Within BTC metadata files, we propose the reference genome in use be specified in columns/attributes named \u201cGenomic Reference\u201d and \u201cGenomic Reference URL\u201d. External Data Data generated through efforts funded by other organizations is referred to as \u201cexternal data\u201d. BTC investigators are free (and encouraged) to utilize external data in BTC work, which will typically play out in one of two ways: Ad-hoc: in which the investigator or their staff downloads external data to local institutional resources (e.g. on-prem compute or cloud) and references in their local BTC analyses; here the investigator and/or staff initiates & performs the collecting, aggregating and storing of external data on their institutional systems DASH: investigator requests that BTC make external easily accessible to other BTC collaborators via DASH; either in raw form directly from the staging area or more formally with BTC identifiers attached so that the identity and provenance are clear In the latter case of external data being assigned BTC IDs, a unique study name will be created to indicate that the dataset is from an external source, following the schema EXT_ . For example, if we were to load BRCA data from TCGA into DASH, one might use TCGA_BRCA as the study name, yielding identifiers for such data that begin with BTC-TCGA_BRCA- and so forth. Attaching BTC identifiers to external data may provide a number of advantages Enabling it to be seamlessly mingled with internal BTC data Then processed and analyzed at scale in downstream pipelines or analysis tools While making the external identity and provenance of the data clear And simplifying later bookkeeping and database tracing when assembling data for publication but should not be interpreted as a claim that BTC now \u201cowns\u201d or is attempting to \u201cre-brand\u201d those external data. Version 0.7.5","title":"  "},{"location":"#quick-documents-links","text":"| BTC Data Science Hub Proposal | Data Coordinator Duties | Technical Instructions on Staging Data | How to Configure AWS CLI |","title":"Quick Documents Links"},{"location":"#btc-data-reference","text":"The aim of this page is to serve as a central point of reference for data handling in Break Through Cancer (BTC), capturing the consensus rubric under which data are generated, annotated, aggregated, governed, and accessed. This includes metadata capture during patient enrollment and sample acquisition, standards and processes for molecular assay data generation and pipelines, data flow diagrams providing simplified views, as well as a FAQ for common questions. In concert with BTC Disease TeamLabs, these norms are being codified by the Data Science TeamLab (DST) as a key element of the data science proposal The system and infrastructure which serves as the convergence point for data science activity within BTC is code-named DASH , short for DA ta S cience H ub; and is informed by numerous standards, including F.A.I.R. data practice and NIH guidelines , and draws heavily from lessons learned and software developed in earlier and sister projects, including HTAN , GDC , and TCGA","title":"BTC Data Reference"},{"location":"#data-life-cycle","text":"Within BTC the flow of data naturally subdivides along the boundaries of institutional and BTC-wide ecosystems: Institutional: data, research, and clinical trial activity typically within the walls of a single instution, performed upon and annotated by institutional systems per their internal practice. Some examples of this could be pre-clinical or basic research results from a single PI lab, or the exported and de-indentified data from a clinical trial data system. DASH: data shared by TeamLabs across institutional boundaries, by way of DASH How DASH maintains identifiers for and provenance of these data is described in more detail below .","title":"Data Life Cycle"},{"location":"#planning-for-data-sharing","text":"Please contact the BTC Programs Team when planning to share data used by or generated in your TeamLab, whether pre-clinical, clinical, or publication data. The PM team will help assess whether there are contractual, institutional, or other encumbrances upon the data that must be cleared first before they may be shared. While planning it's also important to note that: Sharing non-public data via DASH does not confer access to other TeamLabs: such data are initially embargoed, with access limited to members of the submitting TeamLab until the embargo period ends Patient IDs, sample IDs, and related metadata are defined within clinical lab manuals and SOPs: this will help BTC maintain the provenance of material and data as it travels from one institute to another SOPs are in place to remove PHI prior to sharing","title":"Planning for Data Sharing"},{"location":"#sharingsubmitting-data","text":"When data are ready to be shared/analyzed via DASH, please contact the data coordinator(s) at your institution: MD Anderson: Tracee Burnsteel MIT: Charles Demurjian (PI: Stuart Levine) Johns Hopkins: Meredith Wetzel (PI: Elana Fertig) Memorial Sloan Kettering: Eli Havasov (PI: Sohrab Shah) Dana Farber: Siri Palreddy (PI: Rameen Beroukhim) The role of the BTC data coordinator is described here . Your data coordinator and the DASH team will be happy to guide data providers through the process of staging data into cloud buckets( ). The staging area * is a data lake -style abstraction: a semi-organized collection of storage bins, stratified by TeamLab, whose contents are provided \"as is,\" with little (or no) formal validation or annotation. TeamLab members may elect to use such staged data immediately, prior to further curation, as needs dictate. * Originally, we allowed teams to stage their data into cloud buckets and Sharepoint, however we now only allow data to be staged in the cloud.","title":"Sharing/Submitting Data"},{"location":"#data-curation","text":"After staging, many (but not necessarily all) BTC datasets will also be curated, which includes steps such as: validating that shared files do not include PHI, verifying that trial-specific IDs (when applicable) have been associated so that the data may be tracked, and ensuring sufficient metadata have been submitted so that others may productively use the data. As described below , BTC-specific IDs will also be assigned within the DASH database to maintain provenance, enable pan-cancer analysis, and promote data governance (such as sandboxed use during embargo periods). These BTC IDs supplement, rather than replace, any IDs attached at the point of data origination (e.g. in a clinical trial or PI lab) and the mapping between the two will be retained internally by DASH as metadata.","title":"Data Curation"},{"location":"#accessing-data","text":"Both staged and curated data are summarized in our high-level DASHBoard and may be downloaded interactively from the data browser (temporarily disabled during AWS migration) or programmatically via aws cli for many, large files or pipelined analysis. Additional information is available in the technical instructions (ver 0.7) for data sharing . Finally, recall that staged data are offered \"as is,\" while curated data will soon support more advanced use cases such as querying with fine-grained parameters (e.g. gene name) or visual exploration in familiar tools like cBioPortal , cellxgene , or Minerva as appropriate.","title":"Accessing Data"},{"location":"#analysis-and-pipelines","text":"The DST has established joint Protocol and Analysis working groups with disease teams, to: identify analysis needs across TeamLabs, align common SOPs for data generation and QC, coordinate changes as new technologies and needs arise, tie each central analytic pipeline to consumers of its data in each TeamLab, and perform regular check-ins to ensure analytic approaches continue to suit disease TeamLab objectives. For each data type generated across two or more TeamLabs, the DST will provide best-practices pipelines and/or tools for each data level : from Levels 1 and 2 primary data generation (L1, L2) through subsequent L3 and L4 analyses. This work is very active, and a number of analysis pipelines are already available from DFCI , JHU, MDAnderson, NextFlow nf-core and the MIT BioMicroCenter . As these and other pipelines harden towards robust, self-service tools they are also being added to a common, increasingly multi-modal analysis workflow in the BTC Cirro instance . This BTC Cirro instance should be immediately accessible to anyone in BTC via single-sign-on with the same credentials used to access other BTC resources (e.g. SharePoint or Teams). The Cirro platform runs NextFlow and WDL pipelines, and provides powerful tools for computationalists in a modern, easy-to-use interface that is also approachable for non-computationalists. There are over 170 pipeline configurations already available, and we are making project spaces available for each TeamLab that are pre-loaded with that team's data, include all available analysis pipelines, and are by default sandboxed for access only by members of the team. Please contact the DASH team if you would like to contribute pipelines, perform analyses, or would simply like more information.","title":"Analysis and Pipelines"},{"location":"#btc-identifier-scheme","text":"As data are added to DASH they are tagged with subject and sample (biospecimen) identifiers as follows: At minimum such IDs will be attached to BTC clinical trial data; and ideally to BTC pre-clinical, basic research, and external data as appropriate (all by way of the scheme described here ). Note that here \u201cbiospecimen\u201d is preferred over \u201csample\u201d for generality and to capture that samples can be subdivided into multiple portions. The association between data file and biospecimen is maintained as metadata within the DASH database, not within the file identifier itself. To see how this ID scheme might play out, here's what a hypothetical data tree for the first subject (patient) of the first BTC glioblastoma multiforme trial might look like Here 6 needle biopsy cores (samples) were extracted; the first of which has been characterized in multiple assays, yielding 8 distinctly molecular data output files (i.e. one per data type). Each interventional timepoint in a longitudinal trial would yield a new sample (or samples) for that subject. Finally, note that BTC may devise study names which encompass the entire set of data generated by a TeamLab, (e.g. a study name of \"GBM\" that might include ALL data from trial 1, trial 2, and so forth).","title":"BTC Identifier Scheme"},{"location":"#scope","text":"It will help to amplify a point made above in the context of data curation , namely that BTC- identifiers apply only to data AFTER sharing into DASH . These IDs do not replace identifiers attached to data at their point of origin (e.g. in a clinical trial data system, or PI lab research project, or external publication), and in fact those original IDs will be carried along--to the greatest extent possible--as metadata when data are shared into DASH. In other words, DASH does not seek to legislate how data generators identify data within the context of its original use case(s), only how data are identified once they are shared within DASH.","title":"Scope"},{"location":"#data-entities-and-levels","text":"As data progress through the BTC life cycle they are processed and transformed through a series of \u201cdata levels.\u201d For each data context (e.g. clinical, imaging, sequencing, spatial) the constituent files of each data level may differ, but in all cases Level 1 represents raw or uncurated data (e.g. directly from an instrument) and each successive level represents a maturation of that data towards analysis and, eventually, publication and wider utilization. Unless explicitly stated otherwise, we propose BTC data infrastructure, processing and analysis adopt existing GDC + HTAN standards and nomenclature, including for clinical , biospecimen , sequencing and imaging data. For convenience, some of those standards will be excerpted below but we refer the reader back to the original material at the given links for an exhaustive treatment. Each disease study in BTC contributes data from 1 or more enrolled Subjects, who have donated Biospecimens. Data files are generated when biospecimens are assayed by an instrument/protocol or processed in downstream SOPs or analyses. Captured metadata enables tracing of any data file back to its source biospecimen. Level 1 raw data files are derived directly from the corresponding biospecimen, whereas processed level 2-4 data files are linked to lower level parent data files.","title":"Data Entities and Levels"},{"location":"#clinical-data-levels-tiers","text":"The BTC clinical data model consists of three tiers. Tier 1 aligns with Genomic Data Commons (GDC) guidelines for clinical data, while Tiers 2 and 3 are informed by the HTAN extensions to the GDC model . Clinical data in BTC are still evolving as we develop trial forms and SOPs across institutions. Only Tier1 is encompassed thus far, but no data will be ingested into DASH if it is not (a) fully de-identified and (b) accompanied by minimally viable metadata (biospecimen and/or clinical).","title":"Clinical Data Levels (Tiers)"},{"location":"#omic-data-levels","text":"In alignment with TCGA and the NCI Genomic Data Commons, BTC will categorize multi-omic data into four levels: Level Definition Examples 1 Raw data FASTQs, unaligned BAMs 2 Aligned primary data Aligned BAMs 3 Derived biomolecular data Gene expression matrix files, VCFs, etc 4 Sample level summary data t-SNE plot coordinates, etc These will apply to the multiple assay and sequencing modalities (omic data types) envisioned for BTC , including single-cell and single-nucleus RNA Seq (sc/snRNASeq), single-cell ATAC Seq, bulk RNAseq and Bulk DNAseq. We propose that BTC follow the latest GENCODE version for gene annotations, GENCODE Version 43. GENCODE is used for gene definitions by many consortia, including ENCODE, NCI Genomic Data Commons, Human Cell Atlas, and PCAWG (Pan-Cancer Analysis of Whole Genomes). Ensembl gene content is essentially identical to that of GENCODE (FAQ) and interconversion is possible. We further propose BTC adopt GENCODE 43 Gene Transfer Format (GTF) basic gene annotation file (GENCODE 43 GTF) and filtered files (GENCODE 43 GTF with genes only; GENCODE 43 GTF with genes only and retaining only chromosome X copy of pseudoautosomal region) for gene annotation. BTC may also include external data generated with other gene models, as the process of implementing the standard is ongoing. Within BTC metadata files, we propose the reference genome in use be specified in columns/attributes named \u201cGenomic Reference\u201d and \u201cGenomic Reference URL\u201d.","title":"Omic Data Levels"},{"location":"#external-data","text":"Data generated through efforts funded by other organizations is referred to as \u201cexternal data\u201d. BTC investigators are free (and encouraged) to utilize external data in BTC work, which will typically play out in one of two ways: Ad-hoc: in which the investigator or their staff downloads external data to local institutional resources (e.g. on-prem compute or cloud) and references in their local BTC analyses; here the investigator and/or staff initiates & performs the collecting, aggregating and storing of external data on their institutional systems DASH: investigator requests that BTC make external easily accessible to other BTC collaborators via DASH; either in raw form directly from the staging area or more formally with BTC identifiers attached so that the identity and provenance are clear In the latter case of external data being assigned BTC IDs, a unique study name will be created to indicate that the dataset is from an external source, following the schema EXT_ . For example, if we were to load BRCA data from TCGA into DASH, one might use TCGA_BRCA as the study name, yielding identifiers for such data that begin with BTC-TCGA_BRCA- and so forth. Attaching BTC identifiers to external data may provide a number of advantages Enabling it to be seamlessly mingled with internal BTC data Then processed and analyzed at scale in downstream pipelines or analysis tools While making the external identity and provenance of the data clear And simplifying later bookkeeping and database tracing when assembling data for publication but should not be interpreted as a claim that BTC now \u201cowns\u201d or is attempting to \u201cre-brand\u201d those external data.","title":"External Data"},{"location":"#version-075","text":"","title":"Version 0.7.5"},{"location":"about/","text":".navbar { display: none; } DASH Overview Welcome to DASH, the DA ta S cience H ub portal in Break Through Cancer (BTC). DASH is meant to be a central reference for data science across the BTC network, providing an easy-to-remember, one-stop access point for computational methods, analysis piplines, and data; as well as information on the aims and composition of the Data Science TeamLab (DST), how we will work in concert with the disease TeamLabs across BTC, and comprehensive standards and documention on data generation and infrastructure. Each facet of DASH is evolving very rapidly, so please come back regularly! BTC Data Science in Brief The primary goal of the Data Science TeamLab (DST) in BTC is to unify BTC investigators around data and computation, into a collaborative network that will enhance and accelerate all disease research and discovery objectives. By providing essential data infrastructure and advanced computational cancer biology, in support of the scientific objectives and the experimentalist and clinical team members of BTC projects, we aim to increase the efficiency, durability and robustness of all BTC research. By making a dedicated investment in the development of new computational methods and software, we aspire to advance biological questions and themes cutting across all BTC disease teams, including cancer evolution & cellular plasticity spatial determinants of microenvironments and tumor cell immune cell interactions Moreover, in the collaborative spirit of BTC, our network-wide model also provides a unique social component dedicated to mentoring the next generation of outstanding investigators. The data science initiative within BTC thus constitutes a unique and transformative multi-institutional initiative that will be continuously responsive to the scientific needs of diease projects and investigators practice rigorous and secure data engineering, informed by F.A.I.R. principles accelerate advances in computational methods required to achieve BTC scientific aims create robust, benchmarked and hardened software for scaled, systematic deployment maximize the impact of each BTC project by enabling and accelerating pan-cancer analysis; create a collaborative network of data science investigators and trainees to power these objectives For more details, please see the full data science proposal here. How We'll Work Together As noted in these slides excerpted from our kickoff (12-Oct-2022) , the Data Science TeamLab sees itself as Facilitators of disease TeamLab science Innovators of high-resolution, multi-modal analytic methods Weavers of infrastructural fabric linking these together thereby breaking through traditional research silos to foster the widest, deepest, and fastest cross-institutional engagement of BTC expertise, within a secure and well-governed platform. We hope to achieve this through dynamic and transparent collaboration with each disease team, to learn where we may help each other, how, and at what cadence. This may often take the form of data scientists helping to answer a myriad of scientific questions posed by the disease group, co-analyzing data, and using the resulting insights to drive the development of new computational methods. At other moments it might be engineers co-developing a database model, or forms for gathering clinical parameters, or assisting with data upload to cloud storage and automated analysis. At still other points, it might involve co-developing pipeline methods or exploratory visualizations and dashboarding tools, or guiding others in their use. The work will play out in a variety of ways, but this is just the beginning of a transformative experiment in multi-institutional, collaborative science; we know our collective efforts will lead to opportunities and challenges not yet envisioned, but look forward to working with disease teams to identify and prioritize areas of greatest unmet scientific, algorithmic, or technical need and cultivating solutions that accelerate our science. Primary Contacts We are fortunate to have the talents of Benjamin Greenbaum and Kadir Akdemir to coordinate our monthly meeting series and related activity, so for general matters please reach out to them. For administrative questions, please contact Ineke Ceder, and for our proposal aims the primary contacts are as follows: Aim 1 - Best Practices Pipelines: Rameen Beroukhim , Linghua Wang Aim 2 \u2013 Data Infrastructure and Governance: Michael Noble Aim 3 - Algorithms and Methods: Sohrab Shah Aim 4 - Evaluate/Benchmark/Harden Software: Andrew McPherson , Charlie Whitaker Aim 5 - Pan-cancer Analysis: Linghua Wang , Rameen Beroukhim Aim 6 - BTC Data Science Network: Kadir Akdemir , Elana Fertig Data Infrastructure BTC is unique in the foresight and boldness of its commitment to placing collaborative data science at the center of a diverse research portfolio. But realizing that long-term vision will not be easy or quick, so it is worth emphasizing that early versions of infrastructure and tools will be enabling but minimalist; and, like all early-stage work, will look and feel more like exposed foundation and scaffolding. With each successive iteration, however, we will identify what critical needs remain unmet and what features to keep or eliminate, while emphasizing clarity, transparency, and simplicity. Here is a summary of recent thought progress on infrastructure and how that informs planning at several scales. Regular updates will be given to all of BTC as these efforts mature, and detailed plans will be circulated as they emerge. Early, Medium, and Long-Term Planning In the nearest term and as a stopgap measure while hiring staff, finalizing partner SOWs, and gradually assembling infrastructure, we\u2019ve constructed a prototype data lake using the Google Cloud Platform (GCP). While just the first step towards our long-term vision, this reflects our patient \u00fcber alles sense of urgency that to best support ongoing BTC science data must flow . The data lake will provide a central point of aggregation and access, and facilitate immediate sharing within TeamLabs because it does not require extensive build-out nor deep modeling, validation or annotation. We are working closely with clinical data coordinators and thought leaders across BTC to identify SOPs, data and annotations of greatest immediate impact, while prototyping lightweight mechanisms for submission of molecular and clinical data. As these data accumulate, we will also host a BTC-wide dashboard to foster transparency on accrual. In the medium term and drawing from substantial discussion and technical review with stakeholders and technology partners, we will further improve data flow through a pilot with Sage Bionetworks. Guided by a core philosophy of reuse rather than reinvent, using Synapse to validate ingestion will endow our data store with provenance and provable correctness; directly leverage the GCP data lake; stimulate rapid progress by reusing existing standards and open-source components developed in sister projects like HTAN; and reduce development time and cost. As that matures, we\u2019ll begin to assemble and operationalize a standard analysis workflow, which can either make direct use of the data lake or Synapse warehouse. Early versions of the analysis workflow will focus on tools already seeing wide use in the community (e.g. NextFlow Core ) and/or pre-installed in Terra ; but as new methods develop across BTC and beyond we\u2019ll seek to harden them for scale and incorporate into the standard analysis as well. For the long term, and given the complexity and rapid evolution of technology and science in cancer research, we recognize that no single platform addresses our entire slate of data collection, governance, and analysis needs. We will therefore continue to engage a wide range of technology partners\u2014including Verily/Google, Microsoft, Code Ocean, Syntropy, Flywheel, and Seven Bridges; towards defining proof-of-concept pilots to discern areas of mutual collaborative interest and potential philanthropic opportunity, while reaching for continuous improvement of the scientific and clinical capability, governance, reproducibility, scalability, security, and robustness of our system.","title":"  "},{"location":"about/#dash-overview","text":"Welcome to DASH, the DA ta S cience H ub portal in Break Through Cancer (BTC). DASH is meant to be a central reference for data science across the BTC network, providing an easy-to-remember, one-stop access point for computational methods, analysis piplines, and data; as well as information on the aims and composition of the Data Science TeamLab (DST), how we will work in concert with the disease TeamLabs across BTC, and comprehensive standards and documention on data generation and infrastructure. Each facet of DASH is evolving very rapidly, so please come back regularly!","title":"DASH Overview"},{"location":"about/#btc-data-science-in-brief","text":"The primary goal of the Data Science TeamLab (DST) in BTC is to unify BTC investigators around data and computation, into a collaborative network that will enhance and accelerate all disease research and discovery objectives. By providing essential data infrastructure and advanced computational cancer biology, in support of the scientific objectives and the experimentalist and clinical team members of BTC projects, we aim to increase the efficiency, durability and robustness of all BTC research. By making a dedicated investment in the development of new computational methods and software, we aspire to advance biological questions and themes cutting across all BTC disease teams, including cancer evolution & cellular plasticity spatial determinants of microenvironments and tumor cell immune cell interactions Moreover, in the collaborative spirit of BTC, our network-wide model also provides a unique social component dedicated to mentoring the next generation of outstanding investigators. The data science initiative within BTC thus constitutes a unique and transformative multi-institutional initiative that will be continuously responsive to the scientific needs of diease projects and investigators practice rigorous and secure data engineering, informed by F.A.I.R. principles accelerate advances in computational methods required to achieve BTC scientific aims create robust, benchmarked and hardened software for scaled, systematic deployment maximize the impact of each BTC project by enabling and accelerating pan-cancer analysis; create a collaborative network of data science investigators and trainees to power these objectives For more details, please see the full data science proposal here.","title":"BTC Data Science in Brief"},{"location":"about/#how-well-work-together","text":"As noted in these slides excerpted from our kickoff (12-Oct-2022) , the Data Science TeamLab sees itself as Facilitators of disease TeamLab science Innovators of high-resolution, multi-modal analytic methods Weavers of infrastructural fabric linking these together thereby breaking through traditional research silos to foster the widest, deepest, and fastest cross-institutional engagement of BTC expertise, within a secure and well-governed platform. We hope to achieve this through dynamic and transparent collaboration with each disease team, to learn where we may help each other, how, and at what cadence. This may often take the form of data scientists helping to answer a myriad of scientific questions posed by the disease group, co-analyzing data, and using the resulting insights to drive the development of new computational methods. At other moments it might be engineers co-developing a database model, or forms for gathering clinical parameters, or assisting with data upload to cloud storage and automated analysis. At still other points, it might involve co-developing pipeline methods or exploratory visualizations and dashboarding tools, or guiding others in their use. The work will play out in a variety of ways, but this is just the beginning of a transformative experiment in multi-institutional, collaborative science; we know our collective efforts will lead to opportunities and challenges not yet envisioned, but look forward to working with disease teams to identify and prioritize areas of greatest unmet scientific, algorithmic, or technical need and cultivating solutions that accelerate our science.","title":"How We'll Work Together"},{"location":"about/#primary-contacts","text":"We are fortunate to have the talents of Benjamin Greenbaum and Kadir Akdemir to coordinate our monthly meeting series and related activity, so for general matters please reach out to them. For administrative questions, please contact Ineke Ceder, and for our proposal aims the primary contacts are as follows: Aim 1 - Best Practices Pipelines: Rameen Beroukhim , Linghua Wang Aim 2 \u2013 Data Infrastructure and Governance: Michael Noble Aim 3 - Algorithms and Methods: Sohrab Shah Aim 4 - Evaluate/Benchmark/Harden Software: Andrew McPherson , Charlie Whitaker Aim 5 - Pan-cancer Analysis: Linghua Wang , Rameen Beroukhim Aim 6 - BTC Data Science Network: Kadir Akdemir , Elana Fertig","title":"Primary Contacts"},{"location":"about/#data-infrastructure","text":"BTC is unique in the foresight and boldness of its commitment to placing collaborative data science at the center of a diverse research portfolio. But realizing that long-term vision will not be easy or quick, so it is worth emphasizing that early versions of infrastructure and tools will be enabling but minimalist; and, like all early-stage work, will look and feel more like exposed foundation and scaffolding. With each successive iteration, however, we will identify what critical needs remain unmet and what features to keep or eliminate, while emphasizing clarity, transparency, and simplicity. Here is a summary of recent thought progress on infrastructure and how that informs planning at several scales. Regular updates will be given to all of BTC as these efforts mature, and detailed plans will be circulated as they emerge.","title":"Data Infrastructure"},{"location":"about/#early-medium-and-long-term-planning","text":"In the nearest term and as a stopgap measure while hiring staff, finalizing partner SOWs, and gradually assembling infrastructure, we\u2019ve constructed a prototype data lake using the Google Cloud Platform (GCP). While just the first step towards our long-term vision, this reflects our patient \u00fcber alles sense of urgency that to best support ongoing BTC science data must flow . The data lake will provide a central point of aggregation and access, and facilitate immediate sharing within TeamLabs because it does not require extensive build-out nor deep modeling, validation or annotation. We are working closely with clinical data coordinators and thought leaders across BTC to identify SOPs, data and annotations of greatest immediate impact, while prototyping lightweight mechanisms for submission of molecular and clinical data. As these data accumulate, we will also host a BTC-wide dashboard to foster transparency on accrual. In the medium term and drawing from substantial discussion and technical review with stakeholders and technology partners, we will further improve data flow through a pilot with Sage Bionetworks. Guided by a core philosophy of reuse rather than reinvent, using Synapse to validate ingestion will endow our data store with provenance and provable correctness; directly leverage the GCP data lake; stimulate rapid progress by reusing existing standards and open-source components developed in sister projects like HTAN; and reduce development time and cost. As that matures, we\u2019ll begin to assemble and operationalize a standard analysis workflow, which can either make direct use of the data lake or Synapse warehouse. Early versions of the analysis workflow will focus on tools already seeing wide use in the community (e.g. NextFlow Core ) and/or pre-installed in Terra ; but as new methods develop across BTC and beyond we\u2019ll seek to harden them for scale and incorporate into the standard analysis as well. For the long term, and given the complexity and rapid evolution of technology and science in cancer research, we recognize that no single platform addresses our entire slate of data collection, governance, and analysis needs. We will therefore continue to engage a wide range of technology partners\u2014including Verily/Google, Microsoft, Code Ocean, Syntropy, Flywheel, and Seven Bridges; towards defining proof-of-concept pilots to discern areas of mutual collaborative interest and potential philanthropic opportunity, while reaching for continuous improvement of the scientific and clinical capability, governance, reproducibility, scalability, security, and robustness of our system.","title":"Early, Medium, and Long-Term Planning"},{"location":"faq/","text":".navbar, .bs-sidebar { display: none; } BTC Data Science Frequently Asked Questions How should my TeamLab plan to share data in DASH? See the planning section of the data reference . How do I share/submit data in DASH? See the data submission section of the data reference . How can I see what data is in DASH or retrieve it for my work? For interactive exploration, visit the DASH Board and Browse tools. For large-scale downloads or pipelined analysis, use the programmatic methods as described here . What pipelines will be available for analysis? This is discussed in the data reference . What assays (data types) will the pipelines operate upon? This is also discussed in the data reference . Who is responsible for data analysis within BTC disease team labs? There is fuzzy overlap in responsibility for analysis: it should be driven to the greatest extent possible by the disease teamlab, as reflected in their respective budgets, and supported by the Data Science TeamLab (DST) in whatever means necessary (whether computational analytics, data engineering, visualization, etc), but not wholly outsourced from the disease teamlab to the DST. Where that line is drawn for each scientific question or project will likely shift\u2014and may also depend upon trial timelines and staffing\u2014-probably in some cases the data scientists may need to pick up more of the analysis, in others less so. But the overall view, at least initially while BTC finds its operational footing vis-\u00e0-vis data science, is that the DST is not \u201cjust another core, service-oriented facility,\u201d but is a resource of expert collaborators who devise new methods (when needed), or assist with data gathering/engineering, or provide analytic insight and/or assist with interpretation. What kind of biospecimen metadata will be collected? This will likely be different for each trial, but ideally we aim to collect as much as possible, including: Sample acquisition method, e.g. autopsy, biopsy, fine needle aspirate, etc Topography Code, indicating site within the body, e.g. based on ICD-O-3 Collection information e.g. time, duration of ischemia, temperature, etc Processing of parent biospecimen information e.g. fresh, frozen, etc Biospecimen and derivative clinical metadata I.e. Histologic Morphology Code, e.g. based on ICD-O-3 Coordinates for derivative biospecimen from their parent biospecimen Processing of derivative biospecimen for downstream analysis e.g. dissociation, sectioning, analyte isolation This is adapted from HTAN standards and is not intended to be mandatory constraints imposed by the DST upon clinical trial teams or disease team labs; we are in the process of defining the minimum viable set of clinical data elements (CDEs) for BTC projects.","title":"FAQ"},{"location":"faq/#btc-data-science-frequently-asked-questions","text":"How should my TeamLab plan to share data in DASH? See the planning section of the data reference . How do I share/submit data in DASH? See the data submission section of the data reference . How can I see what data is in DASH or retrieve it for my work? For interactive exploration, visit the DASH Board and Browse tools. For large-scale downloads or pipelined analysis, use the programmatic methods as described here . What pipelines will be available for analysis? This is discussed in the data reference . What assays (data types) will the pipelines operate upon? This is also discussed in the data reference . Who is responsible for data analysis within BTC disease team labs? There is fuzzy overlap in responsibility for analysis: it should be driven to the greatest extent possible by the disease teamlab, as reflected in their respective budgets, and supported by the Data Science TeamLab (DST) in whatever means necessary (whether computational analytics, data engineering, visualization, etc), but not wholly outsourced from the disease teamlab to the DST. Where that line is drawn for each scientific question or project will likely shift\u2014and may also depend upon trial timelines and staffing\u2014-probably in some cases the data scientists may need to pick up more of the analysis, in others less so. But the overall view, at least initially while BTC finds its operational footing vis-\u00e0-vis data science, is that the DST is not \u201cjust another core, service-oriented facility,\u201d but is a resource of expert collaborators who devise new methods (when needed), or assist with data gathering/engineering, or provide analytic insight and/or assist with interpretation. What kind of biospecimen metadata will be collected? This will likely be different for each trial, but ideally we aim to collect as much as possible, including: Sample acquisition method, e.g. autopsy, biopsy, fine needle aspirate, etc Topography Code, indicating site within the body, e.g. based on ICD-O-3 Collection information e.g. time, duration of ischemia, temperature, etc Processing of parent biospecimen information e.g. fresh, frozen, etc Biospecimen and derivative clinical metadata I.e. Histologic Morphology Code, e.g. based on ICD-O-3 Coordinates for derivative biospecimen from their parent biospecimen Processing of derivative biospecimen for downstream analysis e.g. dissociation, sectioning, analyte isolation This is adapted from HTAN standards and is not intended to be mandatory constraints imposed by the DST upon clinical trial teams or disease team labs; we are in the process of defining the minimum viable set of clinical data elements (CDEs) for BTC projects.","title":"BTC Data Science Frequently Asked Questions"},{"location":"relnotes/","text":".navbar { display: none; } .bs-sidebar DASH Release Notes 2025_03_27 Welcome to the first installment of DASH release notes in 2025! The Data Science Team (DST) closed 2024 with enormous progress and a strong sense of momentum across BTC, with DASH seeing a 28X increase in volume of data shared by TeamLabs, nearly 200 computational pipelines available in Cirro , and deeply resourced multimodal analyses underway in numerous TeamLabs\u2013fueled by novel BTC methods. In just the first few months of 2025 the volume of data shared to DASH has grown 42% to over 40TB, reflecting contributions from 8 TeamLabs and notably including hundreds of thousands of images from our newest TeamLab, LungRD. This is catalyzing innovative scientific engagement with disease TeamLabs, including collaborations with: The GBM team , helping advance interpretation of single cell RNA sequencing (scRNA-seq), DNA sequencing, and both T-cell and malignant cell clonal tracking data from the needle biopsy trial, to gain deeper insights into cancer evolution; and spearheading data deposition for the trial pilot publication The Ovarian MRD team , to adapt and optimize an approach for longitudinal tracking of drug resistance and co-leading spatial tumor microenvironment profiling to advance our understanding of MRD biology The KRAS team , to advance understanding of cellular and molecular mechanisms of response and resistance to KRAS inhibitors by analyzing scRNA-seq data from clinical specimens and mouse models And contributing to the evaluation and use of spatial omics platforms by analyzing and integrating spatial pilot data through the development and application of novel spatial methods. Another important milestone in multimodal analytics is the GBM Explorer . Developed by Alex Ling (Chiocca Lab, BWH), this APP brings together 5 data modalities (scRNA, TCR, bulkRNA, images, and clinical annotations), enabling clinicians, computational biologists, and engineers to: overlay experimentally measured values on brain biopsy locations in 3D; for rapid co-visualization of measured values from different assays; and easy visualization of patient treatment histories. Thanks to innovative security infrastructure work by Henry Dewhurst at BTC Central, GBM Explorer is the first multimodal analysis APP developed completely within BTC for use across all institutions by members of a single TeamLab, and we look forward to re-using this model to deploy BTC-wide portals for scRNA-seq, scTCR-seq, scBCR-seq and spatial 'omics as well as extend the use of cBioPortal in BTC. 2024_06_03 In this quarter's installment of the DASH release notes we are happy to again report tremendous progress. An incredibly successful Hackathon event, with some 50 registrants across 5 TeamLabs coming together May 20-21 at MSKCC for: 6 training workshops on emerging scRNA, spatial, TCR, and bulkDNA+RNA pipelines in Cirro, coupled with hands-on data analysis and real-time tool construction to explore scientific hypotheses. Each of the working groups performed valuable pipeline, analysis, and exploratory data work; with the winning team taking home a $150 prize for developing a novel approach to using the pool of doublet cells in GBM single-cell RNA data (about 10% of cell population) as markers for strong cell-cell interaction, confirming one such interaction in matched GBM spatial data, then using L-R gene vector analysis to identify a marked gradient effect in a separate, public GBM dataset. Finally, we'd like to thank the MSKCC and BTC organizing, events, and Program Management teams for tremendous catalyzing effort and helping create the sense that this inaugural hackathon is but the first of many to come. The scRNA, spatial, and TCR development teams have released multiple versions of their pipelines, applied in conjunction with disease TeamLabs to emerging data. By way of 6 internal data releases, the total quantity of data shared to DASH has more than doubled since March and number of files nearly tripled; the current 2024-05-21 data version includes over 20TB across some 1200 samples: Thanks to Henry Dewhurst and the Cirro team (especially Nathan Thorpe), we now have an operational, BTC-specific Cirro tenant. This provides additional security sandboxing and configuration flexibility, was used in the aforementioned hackathon, and is the final major step towards production-grade, multi-modal analyses workspaces for each disease TeamLab to be rolled out in Q2 through Q4 of 2024. Multiple software releases of the DASH Board, Browse and Curate APPs Reflecting new metadata export, annotations, and filtering capabilities Improved UI, phone home, and metadata collection, towards self-service by data coordinators 2024_03_04 Welcome to the inaugural edition of the DASH Release Notes, through which we'll provide regular, BTC-wide updates as new datasets, analysis methods & pipelines, infrastructure, and more emerge. With this first installment we're happy to relay: A meeting of the Data Science TeamLab (DST) last week at MD Anderson, with thanks to Kadir Akdemir & MDA colleagues for hosting. This 2-day event showcased considerable progress in the development of analysis methods & pipelines (notably single-cell and bulkRNA, TCR, spatial, and classical bulkDNA approaches); and how they're being woven into an increasingly capable data analysis system for the entire BTC portfolio. Leading to energetic discussion of future science, cross-team interaction, and trainee development. Data snapshot version 2024-02-20 , with over 1K samples and 9TB of data across several TeamLabs: OV-IOC: 335 STIC histoPath images from the Shih Lab @ JHU (courtesy of Yen-Wei Chien) Over 200 files of methylation data from the Cope Lab at JHU Pancreatic: over 450 files including Flow, RNASeq, and path images of MRTX1133-treated mice & cell lines from Dougan Lab @ DFCI (courtesy of Li Qiang) Visium spatialTranscriptomics mouse data from Kalluri Lab @ MDA (courtesy of Kate McAndrews) Cell surface proteomics from Oni Lab @ MIT (courtesy of Salome Shubitidze) More than 4,400 files of GBM data comprising 101 samples and 8 assay data types Contact the DASH team if you still do not have an account for accessing or analyzing data, but please keep in mind that until embargo periods have passed the data created by a TeamLab will generally be accessible only to members of that TeamLab. Data shared to DASH is summarized for easy perusal in the Board app ... ... may be browsed/downloaded from the Browse app or programmatically (e.g. see here or here ) ... analyzed with any of the 20+ pipeline configurations available in Cirro ... with all easily accessed from the DASH home page at dash.breakthroughcancer.org","title":"  "},{"location":"relnotes/#dash-release-notes","text":"","title":"DASH Release Notes"},{"location":"relnotes/#2025_03_27","text":"Welcome to the first installment of DASH release notes in 2025! The Data Science Team (DST) closed 2024 with enormous progress and a strong sense of momentum across BTC, with DASH seeing a 28X increase in volume of data shared by TeamLabs, nearly 200 computational pipelines available in Cirro , and deeply resourced multimodal analyses underway in numerous TeamLabs\u2013fueled by novel BTC methods. In just the first few months of 2025 the volume of data shared to DASH has grown 42% to over 40TB, reflecting contributions from 8 TeamLabs and notably including hundreds of thousands of images from our newest TeamLab, LungRD. This is catalyzing innovative scientific engagement with disease TeamLabs, including collaborations with: The GBM team , helping advance interpretation of single cell RNA sequencing (scRNA-seq), DNA sequencing, and both T-cell and malignant cell clonal tracking data from the needle biopsy trial, to gain deeper insights into cancer evolution; and spearheading data deposition for the trial pilot publication The Ovarian MRD team , to adapt and optimize an approach for longitudinal tracking of drug resistance and co-leading spatial tumor microenvironment profiling to advance our understanding of MRD biology The KRAS team , to advance understanding of cellular and molecular mechanisms of response and resistance to KRAS inhibitors by analyzing scRNA-seq data from clinical specimens and mouse models And contributing to the evaluation and use of spatial omics platforms by analyzing and integrating spatial pilot data through the development and application of novel spatial methods. Another important milestone in multimodal analytics is the GBM Explorer . Developed by Alex Ling (Chiocca Lab, BWH), this APP brings together 5 data modalities (scRNA, TCR, bulkRNA, images, and clinical annotations), enabling clinicians, computational biologists, and engineers to: overlay experimentally measured values on brain biopsy locations in 3D; for rapid co-visualization of measured values from different assays; and easy visualization of patient treatment histories. Thanks to innovative security infrastructure work by Henry Dewhurst at BTC Central, GBM Explorer is the first multimodal analysis APP developed completely within BTC for use across all institutions by members of a single TeamLab, and we look forward to re-using this model to deploy BTC-wide portals for scRNA-seq, scTCR-seq, scBCR-seq and spatial 'omics as well as extend the use of cBioPortal in BTC.","title":"2025_03_27"},{"location":"relnotes/#2024_06_03","text":"In this quarter's installment of the DASH release notes we are happy to again report tremendous progress. An incredibly successful Hackathon event, with some 50 registrants across 5 TeamLabs coming together May 20-21 at MSKCC for: 6 training workshops on emerging scRNA, spatial, TCR, and bulkDNA+RNA pipelines in Cirro, coupled with hands-on data analysis and real-time tool construction to explore scientific hypotheses. Each of the working groups performed valuable pipeline, analysis, and exploratory data work; with the winning team taking home a $150 prize for developing a novel approach to using the pool of doublet cells in GBM single-cell RNA data (about 10% of cell population) as markers for strong cell-cell interaction, confirming one such interaction in matched GBM spatial data, then using L-R gene vector analysis to identify a marked gradient effect in a separate, public GBM dataset. Finally, we'd like to thank the MSKCC and BTC organizing, events, and Program Management teams for tremendous catalyzing effort and helping create the sense that this inaugural hackathon is but the first of many to come. The scRNA, spatial, and TCR development teams have released multiple versions of their pipelines, applied in conjunction with disease TeamLabs to emerging data. By way of 6 internal data releases, the total quantity of data shared to DASH has more than doubled since March and number of files nearly tripled; the current 2024-05-21 data version includes over 20TB across some 1200 samples: Thanks to Henry Dewhurst and the Cirro team (especially Nathan Thorpe), we now have an operational, BTC-specific Cirro tenant. This provides additional security sandboxing and configuration flexibility, was used in the aforementioned hackathon, and is the final major step towards production-grade, multi-modal analyses workspaces for each disease TeamLab to be rolled out in Q2 through Q4 of 2024. Multiple software releases of the DASH Board, Browse and Curate APPs Reflecting new metadata export, annotations, and filtering capabilities Improved UI, phone home, and metadata collection, towards self-service by data coordinators","title":"2024_06_03"},{"location":"relnotes/#2024_03_04","text":"Welcome to the inaugural edition of the DASH Release Notes, through which we'll provide regular, BTC-wide updates as new datasets, analysis methods & pipelines, infrastructure, and more emerge. With this first installment we're happy to relay: A meeting of the Data Science TeamLab (DST) last week at MD Anderson, with thanks to Kadir Akdemir & MDA colleagues for hosting. This 2-day event showcased considerable progress in the development of analysis methods & pipelines (notably single-cell and bulkRNA, TCR, spatial, and classical bulkDNA approaches); and how they're being woven into an increasingly capable data analysis system for the entire BTC portfolio. Leading to energetic discussion of future science, cross-team interaction, and trainee development. Data snapshot version 2024-02-20 , with over 1K samples and 9TB of data across several TeamLabs: OV-IOC: 335 STIC histoPath images from the Shih Lab @ JHU (courtesy of Yen-Wei Chien) Over 200 files of methylation data from the Cope Lab at JHU Pancreatic: over 450 files including Flow, RNASeq, and path images of MRTX1133-treated mice & cell lines from Dougan Lab @ DFCI (courtesy of Li Qiang) Visium spatialTranscriptomics mouse data from Kalluri Lab @ MDA (courtesy of Kate McAndrews) Cell surface proteomics from Oni Lab @ MIT (courtesy of Salome Shubitidze) More than 4,400 files of GBM data comprising 101 samples and 8 assay data types Contact the DASH team if you still do not have an account for accessing or analyzing data, but please keep in mind that until embargo periods have passed the data created by a TeamLab will generally be accessible only to members of that TeamLab. Data shared to DASH is summarized for easy perusal in the Board app ... ... may be browsed/downloaded from the Browse app or programmatically (e.g. see here or here ) ... analyzed with any of the 20+ pipeline configurations available in Cirro ... with all easily accessed from the DASH home page at dash.breakthroughcancer.org","title":"2024_03_04"}]}